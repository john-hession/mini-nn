{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy NN on mnist dataset\n",
    "from components import layers, objectives, activations, utils\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use iris toy dataset as proof of concept\n",
    "data = sklearn.datasets.load_digits()\n",
    "\n",
    "input_size = len(data['data'][0])\n",
    "output_size = len(np.unique(data['target']))\n",
    "\n",
    "X = utils.min_max_normalize(data['data'])\n",
    "# convert labels to one hot\n",
    "y = np.zeros((data['target'].size, output_size), dtype=int)\n",
    "y[np.arange(data['target'].size), data['target']] = 1\n",
    "\n",
    "learn_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the network\n",
    "l1 = layers.Linear(input_size, 128)\n",
    "r1 = activations.ReLu()\n",
    "l2 = layers.Linear(128, 32)\n",
    "r2 = activations.ReLu()\n",
    "l3 = layers.Linear(32, output_size)\n",
    "softm = activations.SoftMax()\n",
    "\n",
    "\n",
    "def forward(input):\n",
    "    # forward pass through the network\n",
    "    x = l1.forward(input)\n",
    "    x = r1.forward(x)\n",
    "    x = l2.forward(x)\n",
    "    x = r2.forward(x)\n",
    "    x = l3.forward(x)\n",
    "    x = softm.forward(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def backwards(grad, learn_rate):\n",
    "    \n",
    "    grad = softm.backward(grad)\n",
    "    grad = l3.backward(grad, learn_rate)\n",
    "    grad = r2.backward(grad)\n",
    "    grad = l2.backward(grad, learn_rate)\n",
    "    grad = r1.backward(grad)\n",
    "    grad = l1.backward(grad, learn_rate)\n",
    "\n",
    "    return\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "loss: 10.340663580286705\n",
      "epoch 2\n",
      "loss: 10.340525604303652\n",
      "epoch 3\n",
      "loss: 10.340509670616331\n",
      "epoch 4\n",
      "loss: 10.340503483443754\n",
      "epoch 5\n",
      "loss: 10.340500191086306\n",
      "epoch 6\n",
      "loss: 10.340498148116078\n",
      "epoch 7\n",
      "loss: 10.340496758309978\n",
      "epoch 8\n",
      "loss: 10.34049575266216\n",
      "epoch 9\n",
      "loss: 10.340494992088653\n",
      "epoch 10\n",
      "loss: 10.340494397249108\n",
      "epoch 11\n",
      "loss: 10.340493919470415\n",
      "epoch 12\n",
      "loss: 10.340493527058781\n",
      "epoch 13\n",
      "loss: 10.340493199376409\n",
      "epoch 14\n",
      "loss: 10.340492921698372\n",
      "epoch 15\n",
      "loss: 10.340492683381077\n",
      "epoch 16\n",
      "loss: 10.340492476730264\n",
      "epoch 17\n",
      "loss: 10.340492295858128\n",
      "epoch 18\n",
      "loss: 10.340492136253403\n",
      "epoch 19\n",
      "loss: 10.340491994395464\n",
      "epoch 20\n",
      "loss: 10.340491867486673\n",
      "epoch 21\n",
      "loss: 10.340491753283132\n",
      "epoch 22\n",
      "loss: 10.34049164997524\n",
      "epoch 23\n",
      "loss: 10.340491556100968\n",
      "epoch 24\n",
      "loss: 10.340491470433383\n",
      "epoch 25\n",
      "loss: 10.340491391946024\n",
      "epoch 26\n",
      "loss: 10.34049131978346\n",
      "epoch 27\n",
      "loss: 10.340491253208898\n",
      "epoch 28\n",
      "loss: 10.340491191604654\n",
      "epoch 29\n",
      "loss: 10.340491134438603\n",
      "epoch 30\n",
      "loss: 10.340491081247073\n",
      "epoch 31\n",
      "loss: 10.340491031632439\n",
      "epoch 32\n",
      "loss: 10.340490985247751\n",
      "epoch 33\n",
      "loss: 10.340490941792075\n",
      "epoch 34\n",
      "loss: 10.34049090099556\n",
      "epoch 35\n",
      "loss: 10.340490862624133\n",
      "epoch 36\n",
      "loss: 10.34049082646779\n",
      "epoch 37\n",
      "loss: 10.340490792341049\n",
      "epoch 38\n",
      "loss: 10.340490760078879\n",
      "epoch 39\n",
      "loss: 10.34049072953382\n",
      "epoch 40\n",
      "loss: 10.340490700572671\n",
      "epoch 41\n",
      "loss: 10.340490673076335\n",
      "epoch 42\n",
      "loss: 10.340490646932501\n",
      "epoch 43\n",
      "loss: 10.340490622047755\n",
      "epoch 44\n",
      "loss: 10.340490598333192\n",
      "epoch 45\n",
      "loss: 10.340490575709135\n",
      "epoch 46\n",
      "loss: 10.340490554103232\n",
      "epoch 47\n",
      "loss: 10.340490533447527\n",
      "epoch 48\n",
      "loss: 10.34049051368214\n",
      "epoch 49\n",
      "loss: 10.34049049475098\n",
      "epoch 50\n",
      "loss: 10.340490476602602\n",
      "epoch 51\n",
      "loss: 10.340490459189825\n",
      "epoch 52\n",
      "loss: 10.34049044246888\n",
      "epoch 53\n",
      "loss: 10.340490426398606\n",
      "epoch 54\n",
      "loss: 10.340490410942982\n",
      "epoch 55\n",
      "loss: 10.340490396067647\n",
      "epoch 56\n",
      "loss: 10.340490381740723\n",
      "epoch 57\n",
      "loss: 10.340490367932345\n",
      "epoch 58\n",
      "loss: 10.340490354614959\n",
      "epoch 59\n",
      "loss: 10.340490341766271\n",
      "epoch 60\n",
      "loss: 10.34049032936033\n",
      "epoch 61\n",
      "loss: 10.340490317373842\n",
      "epoch 62\n",
      "loss: 10.340490305786036\n",
      "epoch 63\n",
      "loss: 10.340490294577277\n",
      "epoch 64\n",
      "loss: 10.340490283728993\n",
      "epoch 65\n",
      "loss: 10.340490273224841\n",
      "epoch 66\n",
      "loss: 10.340490263048778\n",
      "epoch 67\n",
      "loss: 10.340490253185658\n",
      "epoch 68\n",
      "loss: 10.340490243621245\n",
      "epoch 69\n",
      "loss: 10.340490234342372\n",
      "epoch 70\n",
      "loss: 10.340490225336366\n",
      "epoch 71\n",
      "loss: 10.340490216591498\n",
      "epoch 72\n",
      "loss: 10.340490208096663\n",
      "epoch 73\n",
      "loss: 10.34049019984144\n",
      "epoch 74\n",
      "loss: 10.340490191815706\n",
      "epoch 75\n",
      "loss: 10.340490184009587\n",
      "epoch 76\n",
      "loss: 10.340490176414827\n",
      "epoch 77\n",
      "loss: 10.340490169023028\n",
      "epoch 78\n",
      "loss: 10.340490161826043\n",
      "epoch 79\n",
      "loss: 10.340490154816438\n",
      "epoch 80\n",
      "loss: 10.34049014798693\n",
      "epoch 81\n",
      "loss: 10.340490141330879\n",
      "epoch 82\n",
      "loss: 10.340490134841744\n",
      "epoch 83\n",
      "loss: 10.340490128512977\n",
      "epoch 84\n",
      "loss: 10.340490122338574\n",
      "epoch 85\n",
      "loss: 10.340490116313486\n",
      "epoch 86\n",
      "loss: 10.34049011043245\n",
      "epoch 87\n",
      "loss: 10.340490104690419\n",
      "epoch 88\n",
      "loss: 10.340490099082503\n",
      "epoch 89\n",
      "loss: 10.340490093604087\n",
      "epoch 90\n",
      "loss: 10.340490088250782\n",
      "epoch 91\n",
      "loss: 10.340490083018304\n",
      "epoch 92\n",
      "loss: 10.340490077902693\n",
      "epoch 93\n",
      "loss: 10.340490072900156\n",
      "epoch 94\n",
      "loss: 10.340490068006982\n",
      "epoch 95\n",
      "loss: 10.340490063219534\n",
      "epoch 96\n",
      "loss: 10.340490058534577\n",
      "epoch 97\n",
      "loss: 10.340490053948791\n",
      "epoch 98\n",
      "loss: 10.34049004945916\n",
      "epoch 99\n",
      "loss: 10.340490045062632\n",
      "epoch 100\n",
      "loss: 10.340490040756405\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(100):\n",
    "    running_loss = 0\n",
    "    print(f'epoch {epoch+1}')\n",
    "    for i in range(len(X)):\n",
    "        pred = forward(np.expand_dims(X[i],axis=0))\n",
    "        loss_fn = objectives.CrossEntropyLoss(pred, y[i])\n",
    "        loss = loss_fn.forward()\n",
    "        grad = loss_fn.backward()\n",
    "        backwards(grad, learn_rate)\n",
    "        running_loss += loss\n",
    "\n",
    "    print(f'loss: {running_loss/len(X)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
