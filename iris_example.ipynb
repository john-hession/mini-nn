{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73482fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy NN on iris dataset\n",
    "from components import layers, objectives, activations, utils\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61603f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use iris toy dataset as proof of concept\n",
    "data = sklearn.datasets.load_iris()\n",
    "X = utils.min_max_normalize(data['data'])\n",
    "y = data['target']\n",
    "y[y != 1] = y[y != 1]*0\n",
    "\n",
    "input_size = len(data['data'][0])\n",
    "learn_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6557050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the network\n",
    "l1 = layers.Linear(4, 8)\n",
    "r1 = activations.ReLu()\n",
    "l2 = layers.Linear(8, 4)\n",
    "r2 = activations.ReLu()\n",
    "l3 = layers.Linear(4, 1)\n",
    "sig = activations.Sigmoid()\n",
    "\n",
    "\n",
    "def forward(input):\n",
    "    # forward pass through the network\n",
    "    x = l1.forward(input)\n",
    "    x = r1.forward(x)\n",
    "    x = l2.forward(x)\n",
    "    x = r2.forward(x)\n",
    "    x = l3.forward(x)\n",
    "    x = sig.forward(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def backwards(grad, learn_rate):\n",
    "    \n",
    "    grad = sig.backward(grad)\n",
    "    grad = l3.backward(grad, learn_rate)\n",
    "    grad = r2.backward(grad)\n",
    "    grad = l2.backward(grad, learn_rate)\n",
    "    grad = r1.backward(grad)\n",
    "    grad = l1.backward(grad, learn_rate)\n",
    "\n",
    "\n",
    "    return\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f9b2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "loss: 0.28014548889434604\n",
      "epoch 2\n",
      "loss: 0.24445462896154851\n",
      "epoch 3\n",
      "loss: 0.23610345108000536\n",
      "epoch 4\n",
      "loss: 0.23140536419141347\n",
      "epoch 5\n",
      "loss: 0.22807461898533854\n",
      "epoch 6\n",
      "loss: 0.22560258568657962\n",
      "epoch 7\n",
      "loss: 0.2237110562544124\n",
      "epoch 8\n",
      "loss: 0.22221827096008306\n",
      "epoch 9\n",
      "loss: 0.22101011975639376\n",
      "epoch 10\n",
      "loss: 0.22003644709237813\n",
      "epoch 11\n",
      "loss: 0.21947405156738867\n",
      "epoch 12\n",
      "loss: 0.21915703363808856\n",
      "epoch 13\n",
      "loss: 0.2189175481915207\n",
      "epoch 14\n",
      "loss: 0.21866160359714604\n",
      "epoch 15\n",
      "loss: 0.21846508139002807\n",
      "epoch 16\n",
      "loss: 0.21830021575837028\n",
      "epoch 17\n",
      "loss: 0.21811925642908506\n",
      "epoch 18\n",
      "loss: 0.21797840823976058\n",
      "epoch 19\n",
      "loss: 0.21783024293631773\n",
      "epoch 20\n",
      "loss: 0.21772594088336253\n",
      "epoch 21\n",
      "loss: 0.21761542516448093\n",
      "epoch 22\n",
      "loss: 0.21753292628811802\n",
      "epoch 23\n",
      "loss: 0.21743652075193953\n",
      "epoch 24\n",
      "loss: 0.21734739520819024\n",
      "epoch 25\n",
      "loss: 0.21726266940847352\n",
      "epoch 26\n",
      "loss: 0.21719481283230324\n",
      "epoch 27\n",
      "loss: 0.21711617752773718\n",
      "epoch 28\n",
      "loss: 0.2170077816386338\n",
      "epoch 29\n",
      "loss: 0.2169618446097239\n",
      "epoch 30\n",
      "loss: 0.21690944947899213\n",
      "epoch 31\n",
      "loss: 0.21683586415641604\n",
      "epoch 32\n",
      "loss: 0.21676223262093822\n",
      "epoch 33\n",
      "loss: 0.2166889893478977\n",
      "epoch 34\n",
      "loss: 0.21661642672884757\n",
      "epoch 35\n",
      "loss: 0.21654831500560642\n",
      "epoch 36\n",
      "loss: 0.21650163759413754\n",
      "epoch 37\n",
      "loss: 0.21643736039747183\n",
      "epoch 38\n",
      "loss: 0.21637234672824565\n",
      "epoch 39\n",
      "loss: 0.2163071311738297\n",
      "epoch 40\n",
      "loss: 0.21624600986955736\n",
      "epoch 41\n",
      "loss: 0.21618286135006742\n",
      "epoch 42\n",
      "loss: 0.21611991353123977\n",
      "epoch 43\n",
      "loss: 0.2160594155885134\n",
      "epoch 44\n",
      "loss: 0.21599456640984477\n",
      "epoch 45\n",
      "loss: 0.21589858697879108\n",
      "epoch 46\n",
      "loss: 0.21588062650117706\n",
      "epoch 47\n",
      "loss: 0.21581730030049945\n",
      "epoch 48\n",
      "loss: 0.21575983589410175\n",
      "epoch 49\n",
      "loss: 0.21569986283466175\n",
      "epoch 50\n",
      "loss: 0.21564031254195043\n",
      "epoch 51\n",
      "loss: 0.21557878802009312\n",
      "epoch 52\n",
      "loss: 0.21552345472158949\n",
      "epoch 53\n",
      "loss: 0.21546511249731054\n",
      "epoch 54\n",
      "loss: 0.21540625737989616\n",
      "epoch 55\n",
      "loss: 0.21535046962280197\n",
      "epoch 56\n",
      "loss: 0.21529197737001046\n",
      "epoch 57\n",
      "loss: 0.21523671257162788\n",
      "epoch 58\n",
      "loss: 0.2151793120427926\n",
      "epoch 59\n",
      "loss: 0.2151208901974033\n",
      "epoch 60\n",
      "loss: 0.2150681670999795\n",
      "epoch 61\n",
      "loss: 0.21501782008043635\n",
      "epoch 62\n",
      "loss: 0.21496249938881812\n",
      "epoch 63\n",
      "loss: 0.2149064066190239\n",
      "epoch 64\n",
      "loss: 0.21484974259463216\n",
      "epoch 65\n",
      "loss: 0.21479563509989505\n",
      "epoch 66\n",
      "loss: 0.21473367055600132\n",
      "epoch 67\n",
      "loss: 0.21467552240232768\n",
      "epoch 68\n",
      "loss: 0.2145873084504031\n",
      "epoch 69\n",
      "loss: 0.2145517147660263\n",
      "epoch 70\n",
      "loss: 0.21445749529639352\n",
      "epoch 71\n",
      "loss: 0.21442710939468124\n",
      "epoch 72\n",
      "loss: 0.21435767954825455\n",
      "epoch 73\n",
      "loss: 0.2142991990936757\n",
      "epoch 74\n",
      "loss: 0.21423324235971933\n",
      "epoch 75\n",
      "loss: 0.21419444932519616\n",
      "epoch 76\n",
      "loss: 0.21411893622212783\n",
      "epoch 77\n",
      "loss: 0.21404942507540725\n",
      "epoch 78\n",
      "loss: 0.21399138481821936\n",
      "epoch 79\n",
      "loss: 0.21392260851311942\n",
      "epoch 80\n",
      "loss: 0.21386484593803365\n",
      "epoch 81\n",
      "loss: 0.21379595510447438\n",
      "epoch 82\n",
      "loss: 0.21373662317732703\n",
      "epoch 83\n",
      "loss: 0.21366589999574392\n",
      "epoch 84\n",
      "loss: 0.21360532414545186\n",
      "epoch 85\n",
      "loss: 0.21353712377168152\n",
      "epoch 86\n",
      "loss: 0.21346299151742498\n",
      "epoch 87\n",
      "loss: 0.21339956847626382\n",
      "epoch 88\n",
      "loss: 0.2132887077758707\n",
      "epoch 89\n",
      "loss: 0.21324858071180125\n",
      "epoch 90\n",
      "loss: 0.21313868572132375\n",
      "epoch 91\n",
      "loss: 0.2130583296512375\n",
      "epoch 92\n",
      "loss: 0.21301592351974133\n",
      "epoch 93\n",
      "loss: 0.21291253123136442\n",
      "epoch 94\n",
      "loss: 0.21283046760137375\n",
      "epoch 95\n",
      "loss: 0.21274938242232203\n",
      "epoch 96\n",
      "loss: 0.21266819130004688\n",
      "epoch 97\n",
      "loss: 0.21258624137150828\n",
      "epoch 98\n",
      "loss: 0.21250312901217108\n",
      "epoch 99\n",
      "loss: 0.2124185937589606\n",
      "epoch 100\n",
      "loss: 0.21233399718500376\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(100):\n",
    "    running_loss = 0\n",
    "    print(f'epoch {epoch+1}')\n",
    "    for i in range(len(X)):\n",
    "        pred = forward(np.expand_dims(X[i],axis=0))\n",
    "        loss_fn = objectives.MSELoss(pred, y[i])\n",
    "        loss = loss_fn.forward()\n",
    "        grad = loss_fn.backward(learn_rate)\n",
    "        backwards(grad, learn_rate)\n",
    "        running_loss += loss\n",
    "\n",
    "    print(f'loss: {running_loss/len(X)}')\n",
    "\n",
    "# seems like the network is underfititng the data, predicting average value\n",
    "# likely due to small number of samples, minmal dimensions, and class imbalance. NN is not ideal tool for this problem.\n",
    "# not worth test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
